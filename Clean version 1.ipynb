{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from supervised.automl import AutoML\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_73781/963998424.py:9: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sid</th>\n",
       "      <th>market_cap_usd</th>\n",
       "      <th>price_close_usd</th>\n",
       "      <th>trading_volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>795.551595</td>\n",
       "      <td>31.984442</td>\n",
       "      <td>4348.168854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>7009.859884</td>\n",
       "      <td>138.910387</td>\n",
       "      <td>18736.503774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>5887.819200</td>\n",
       "      <td>449.156804</td>\n",
       "      <td>50930.600842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>6879.403292</td>\n",
       "      <td>265.277646</td>\n",
       "      <td>70100.691097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>5909.939219</td>\n",
       "      <td>75.278946</td>\n",
       "      <td>74092.584406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       sid  market_cap_usd  price_close_usd  trading_volume  \\\n",
       "0 2015-03-31  SID-0000      795.551595        31.984442     4348.168854   \n",
       "1 2015-06-30  SID-0000     7009.859884       138.910387    18736.503774   \n",
       "2 2015-09-30  SID-0000     5887.819200       449.156804    50930.600842   \n",
       "3 2015-12-31  SID-0000     6879.403292       265.277646    70100.691097   \n",
       "4 2016-03-31  SID-0000     5909.939219        75.278946    74092.584406   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_dataset(n_actions=50, start_date=\"2010-01-01\", end_date=\"2020-12-31\"):\n",
    "    \"\"\"\n",
    "    Génère un DataFrame fictif avec des données temporelles pour plusieurs actions.\n",
    "    - n_actions : nombre d'actions uniques (identifiants `sid`).\n",
    "    - start_date : date de début.\n",
    "    - end_date : date de fin.\n",
    "    \"\"\"\n",
    "    # Générer une plage de dates quotidienne\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=\"Q\")  # Fréquence trimestrielle\n",
    "    \n",
    "    # Générer des identifiants pour les actions\n",
    "    sids = [f\"SID-{i:04d}\" for i in range(n_actions)]\n",
    "    \n",
    "    # Liste pour stocker les données\n",
    "    data = []\n",
    "    \n",
    "    for sid in sids:\n",
    "        for date in date_range:\n",
    "            # Générer des valeurs aléatoires pour les variables explicatives et la cible\n",
    "            market_cap_usd = np.random.uniform(100, 10000)  # Capitalisation aléatoire\n",
    "            price_close_usd = np.random.uniform(10, 500)    # Prix de clôture\n",
    "            trading_volume = np.random.uniform(1000, 100000)  # Volume de trading\n",
    "            target = np.random.choice([0, 1])  # Variable cible (0 ou 1)\n",
    "            \n",
    "            # Ajouter la ligne au dataset\n",
    "            data.append([date, sid, market_cap_usd, price_close_usd, trading_volume, target])\n",
    "    \n",
    "    # Convertir en DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"date\", \"sid\", \"market_cap_usd\", \"price_close_usd\", \"trading_volume\", \"target\"])\n",
    "    return df\n",
    "\n",
    "# Générer un dataset fictif\n",
    "df_random = generate_random_dataset(n_actions=10, start_date=\"2015-01-01\", end_date=\"2020-12-31\")\n",
    "\n",
    "# Afficher un aperçu\n",
    "df_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rolling_windows(data, date_col, target_col, train_years, val_years, test_years, buffer_months):\n",
    "    \"\"\"\n",
    "    Pipeline direct pour la rolling window avec AutoML.\n",
    "    \"\"\"\n",
    "    data[date_col] = pd.to_datetime(data[date_col])  # Assurer le bon format de date\n",
    "    start_date = data[date_col].min()\n",
    "    end_date = data[date_col].max()\n",
    "\n",
    "    predictions_all = []  # Liste pour stocker toutes les prédictions\n",
    "\n",
    "    while start_date + relativedelta(years=train_years + val_years + test_years) <= end_date:\n",
    "        # Définir les périodes\n",
    "        train_end = start_date + relativedelta(years=train_years) - pd.Timedelta(days=1)\n",
    "        tampon_1_start = train_end + pd.Timedelta(days=1)\n",
    "        tampon_1_end = tampon_1_start + relativedelta(months=buffer_months) - pd.Timedelta(days=1)\n",
    "        val_start = tampon_1_end + pd.Timedelta(days=1)\n",
    "        val_end = val_start + relativedelta(years=val_years) - pd.Timedelta(days=1)\n",
    "        tampon_2_start = val_end + pd.Timedelta(days=1)\n",
    "        tampon_2_end = tampon_2_start + relativedelta(months=buffer_months) - pd.Timedelta(days=1)\n",
    "        test_start = tampon_2_end + pd.Timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=test_years) - pd.Timedelta(days=1)\n",
    "\n",
    "        # Filtrer les données pour chaque période\n",
    "        train_data = data.loc[(data[date_col] >= start_date) & (data[date_col] <= train_end)]\n",
    "        val_data = data.loc[(data[date_col] >= val_start) & (data[date_col] <= val_end)]\n",
    "        test_data = data.loc[(data[date_col] >= test_start) & (data[date_col] <= test_end)]\n",
    "\n",
    "        # Configurer et entraîner AutoML\n",
    "        automl = AutoML(mode=\"Perform\", algorithms=[\"Xgboost\"])\n",
    "        automl.fit(\n",
    "            train_data.drop(columns=[target_col, date_col]),\n",
    "            train_data[target_col]\n",
    "        )\n",
    "\n",
    "        # Prédire sur le test set\n",
    "        test_preds = test_data[[date_col, target_col]].copy()\n",
    "        test_preds[\"predicted\"] = automl.predict(test_data.drop(columns=[target_col, date_col]))\n",
    "        test_preds[\"window\"] = f\"{start_date.year}-{test_end.year}\"  # Identifier la fenêtre\n",
    "\n",
    "        # Sauvegarder les prédictions\n",
    "        predictions_all.append(test_preds)\n",
    "\n",
    "        # Avancer la fenêtre\n",
    "        start_date += relativedelta(years=1)\n",
    "\n",
    "    # Concaténer toutes les prédictions\n",
    "    predictions_df = pd.concat(predictions_all, ignore_index=True)\n",
    "\n",
    "    return print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rolling_windows(data, date_col, target_col, train_years, val_years, test_years, buffer_months):\n",
    "    \"\"\"\n",
    "    Pipeline direct pour la rolling window avec AutoML et cross-validation personnalisée.\n",
    "    \"\"\"\n",
    "    data[date_col] = pd.to_datetime(data[date_col])  # Assurer le bon format de date\n",
    "    start_date = data[date_col].min()\n",
    "    end_date = data[date_col].max()\n",
    "\n",
    "    predictions_all = []  # Liste pour stocker toutes les prédictions\n",
    "\n",
    "    while start_date + relativedelta(years=train_years + val_years + test_years) <= end_date:\n",
    "        # Définir les périodes\n",
    "        train_end = start_date + relativedelta(years=train_years) - pd.Timedelta(days=1)\n",
    "        tampon_1_start = train_end + pd.Timedelta(days=1)\n",
    "        tampon_1_end = tampon_1_start + relativedelta(months=buffer_months) - pd.Timedelta(days=1)\n",
    "        val_start = tampon_1_end + pd.Timedelta(days=1)\n",
    "        val_end = val_start + relativedelta(years=val_years) - pd.Timedelta(days=1)\n",
    "        tampon_2_start = val_end + pd.Timedelta(days=1)\n",
    "        tampon_2_end = tampon_2_start + relativedelta(months=buffer_months) - pd.Timedelta(days=1)\n",
    "        test_start = tampon_2_end + pd.Timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=test_years) - pd.Timedelta(days=1)\n",
    "\n",
    "        # Filtrer les données pour chaque période\n",
    "        train_data = data.loc[(data[date_col] >= start_date) & (data[date_col] <= train_end)]\n",
    "        val_data = data.loc[(data[date_col] >= val_start) & (data[date_col] <= val_end)]\n",
    "        test_data = data.loc[(data[date_col] >= test_start) & (data[date_col] <= test_end)]\n",
    "\n",
    "        # Générer les indices pour la cross-validation personnalisée\n",
    "        custom_cv = [(train_data.index, val_data.index)]\n",
    "\n",
    "        # Configurer et entraîner AutoML avec validation personnalisée\n",
    "        automl = AutoML(\n",
    "            mode=\"Perform\",\n",
    "            algorithms=[\"Xgboost\"]\n",
    "        )\n",
    "        \n",
    "        automl.fit(\n",
    "            train_data.drop(columns=[target_col, date_col]),\n",
    "            train_data[target_col], cv=custom_cv\n",
    "        )\n",
    "\n",
    "        # Prédire sur le test set\n",
    "        test_preds = test_data[[date_col, target_col]].copy()\n",
    "        test_preds[\"predicted\"] = automl.predict(test_data.drop(columns=[target_col, date_col]))\n",
    "        test_preds[\"window\"] = f\"{start_date.year}-{test_end.year}\"  # Identifier la fenêtre\n",
    "\n",
    "        # Sauvegarder les prédictions\n",
    "        predictions_all.append(test_preds)\n",
    "\n",
    "        # Avancer la fenêtre\n",
    "        start_date += relativedelta(years=1)\n",
    "\n",
    "    # Concaténer toutes les prédictions\n",
    "    predictions_df = pd.concat(predictions_all, ignore_index=True)\n",
    "\n",
    "    return predictions_df  # Retourner le DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_4\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.670802 trained in 7.37 seconds (1-sample predict time 0.0069 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.66521 trained in 2.46 seconds (1-sample predict time 0.0066 seconds)\n",
      "3_Xgboost logloss 0.673821 trained in 1.53 seconds (1-sample predict time 0.0063 seconds)\n",
      "4_Xgboost logloss 0.691386 trained in 1.08 seconds (1-sample predict time 0.0066 seconds)\n",
      "5_Xgboost logloss 0.691386 trained in 1.15 seconds (1-sample predict time 0.0071 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_sum_price_close_usd\n",
      "Add Golden Feature: trading_volume_sum_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_price_close_usd\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_sum_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_trading_volume\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "2_Xgboost_GoldenFeatures logloss 0.668285 trained in 1.69 seconds (1-sample predict time 0.0174 seconds)\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.677146 trained in 1.81 seconds (1-sample predict time 0.0174 seconds)\n",
      "3_Xgboost_GoldenFeatures logloss 0.676053 trained in 1.87 seconds (1-sample predict time 0.0178 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "2_Xgboost_RandomFeature logloss 0.663092 trained in 1.59 seconds (1-sample predict time 0.0082 seconds)\n",
      "Drop features ['random_feature', 'price_close_usd', 'sid']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "2_Xgboost_SelectedFeatures logloss 0.648154 trained in 1.86 seconds (1-sample predict time 0.0071 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_SelectedFeatures logloss 0.648309 trained in 1.88 seconds (1-sample predict time 0.0069 seconds)\n",
      "7_Xgboost_SelectedFeatures logloss 0.648361 trained in 1.88 seconds (1-sample predict time 0.007 seconds)\n",
      "8_Xgboost logloss 0.665126 trained in 1.78 seconds (1-sample predict time 0.0063 seconds)\n",
      "9_Xgboost logloss 0.665459 trained in 1.78 seconds (1-sample predict time 0.0069 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_SelectedFeatures logloss 0.640808 trained in 1.95 seconds (1-sample predict time 0.0068 seconds)\n",
      "11_Xgboost_SelectedFeatures logloss 0.642017 trained in 2.21 seconds (1-sample predict time 0.0063 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.640808 trained in 0.88 seconds (1-sample predict time 0.0069 seconds)\n",
      "AutoML fit time: 44.46 seconds\n",
      "AutoML best model: 10_Xgboost_SelectedFeatures\n",
      "AutoML directory: AutoML_5\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.671811 trained in 1.84 seconds (1-sample predict time 0.007 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.683018 trained in 1.25 seconds (1-sample predict time 0.0068 seconds)\n",
      "3_Xgboost logloss 0.673216 trained in 1.56 seconds (1-sample predict time 0.0069 seconds)\n",
      "4_Xgboost logloss 0.691386 trained in 0.96 seconds (1-sample predict time 0.0072 seconds)\n",
      "5_Xgboost logloss 0.691386 trained in 1.07 seconds (1-sample predict time 0.0065 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: trading_volume_sum_price_close_usd\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Add Golden Feature: market_cap_usd_ratio_price_close_usd\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: trading_volume_sum_market_cap_usd\n",
      "Add Golden Feature: trading_volume_ratio_price_close_usd\n",
      "Add Golden Feature: market_cap_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_ratio_market_cap_usd\n",
      "Created 10 Golden Features in 0.03 seconds.\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.687383 trained in 1.75 seconds (1-sample predict time 0.018 seconds)\n",
      "3_Xgboost_GoldenFeatures logloss 0.689085 trained in 1.85 seconds (1-sample predict time 0.018 seconds)\n",
      "2_Xgboost_GoldenFeatures logloss 0.67453 trained in 1.86 seconds (1-sample predict time 0.0175 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "1_Default_Xgboost_RandomFeature logloss 0.666928 trained in 1.85 seconds (1-sample predict time 0.0083 seconds)\n",
      "Drop features ['random_feature', 'trading_volume', 'sid', 'price_close_usd']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "1_Default_Xgboost_SelectedFeatures logloss 0.633281 trained in 3.09 seconds (1-sample predict time 0.0066 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_SelectedFeatures logloss 0.632324 trained in 3.21 seconds (1-sample predict time 0.0064 seconds)\n",
      "7_Xgboost_SelectedFeatures logloss 0.632812 trained in 2.96 seconds (1-sample predict time 0.0065 seconds)\n",
      "8_Xgboost logloss 0.676106 trained in 2.06 seconds (1-sample predict time 0.0061 seconds)\n",
      "9_Xgboost logloss 0.673216 trained in 2.05 seconds (1-sample predict time 0.0062 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_SelectedFeatures logloss 0.632324 trained in 3.95 seconds (1-sample predict time 0.0061 seconds)\n",
      "11_Xgboost_SelectedFeatures logloss 0.632812 trained in 3.14 seconds (1-sample predict time 0.0061 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.627321 trained in 0.88 seconds (1-sample predict time 0.0312 seconds)\n",
      "AutoML fit time: 45.35 seconds\n",
      "AutoML best model: Ensemble\n",
      "        date  target  predicted     window\n",
      "0 2018-06-30       1          1  2015-2019\n",
      "1 2018-09-30       1          1  2015-2019\n",
      "2 2018-12-31       0          1  2015-2019\n",
      "3 2019-03-31       0          0  2015-2019\n",
      "4 2018-06-30       1          1  2015-2019\n",
      "Accuracy globale : 48.75%\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline_rolling_windows(\n",
    "    data=df_random,           # Votre DataFrame d'entrée\n",
    "    date_col=\"date\",          # Colonne des dates\n",
    "    target_col=\"target\",      # Colonne cible (0 ou 1)\n",
    "    train_years=2,            # 2 ans pour l'entraînement\n",
    "    val_years=1,              # 1 an pour la validation\n",
    "    test_years=1,             # 1 an pour le test\n",
    "    buffer_months=1           # Tampon de 1 mois\n",
    ")\n",
    "\n",
    "# Afficher un aperçu des prédictions\n",
    "print(predictions.head())\n",
    "\n",
    "# Analyser les résultats\n",
    "accuracy = (predictions[\"predicted\"] == predictions[\"target\"]).mean()\n",
    "print(f\"Accuracy globale : {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  target  predicted     window\n",
       "0  2018-06-30       1          1  2015-2019\n",
       "1  2018-09-30       1          1  2015-2019\n",
       "2  2018-12-31       0          1  2015-2019\n",
       "3  2019-03-31       0          0  2015-2019\n",
       "4  2018-06-30       1          1  2015-2019\n",
       "..        ...     ...        ...        ...\n",
       "75 2020-03-31       1          1  2016-2020\n",
       "76 2019-06-30       0          1  2016-2020\n",
       "77 2019-09-30       1          0  2016-2020\n",
       "78 2019-12-31       1          0  2016-2020\n",
       "79 2020-03-31       1          1  2016-2020\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rolling_windows(data, date_col, target_col, train_years, val_years, test_years, buffer_months=0):\n",
    "    \"\"\"\n",
    "    Pipeline direct pour la rolling window avec AutoML et cross-validation personnalisée.\n",
    "    Ajoute les périodes dans le DataFrame final pour validation.\n",
    "    \"\"\"\n",
    "    # Conversion de la colonne date\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    start_date = data[date_col].min()\n",
    "    end_date = data[date_col].max()\n",
    "\n",
    "    predictions_all = []  # Liste pour stocker toutes les prédictions\n",
    "\n",
    "    while start_date + relativedelta(years=train_years + val_years + test_years) <= end_date:\n",
    "        # Définir les périodes\n",
    "        train_end = start_date + relativedelta(years=train_years) - pd.Timedelta(days=1)\n",
    "        tampon_1_end = train_end + relativedelta(months=buffer_months)\n",
    "        val_start = tampon_1_end + pd.Timedelta(days=1)\n",
    "        val_end = val_start + relativedelta(years=val_years) - pd.Timedelta(days=1)\n",
    "        tampon_2_end = val_end + relativedelta(months=buffer_months)\n",
    "        test_start = tampon_2_end + pd.Timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=test_years) - pd.Timedelta(days=1)\n",
    "\n",
    "        # Filtrer les données\n",
    "        train_data = data.loc[(data[date_col] >= start_date) & (data[date_col] <= train_end)]\n",
    "        val_data = data.loc[(data[date_col] >= val_start) & (data[date_col] <= val_end)]\n",
    "        test_data = data.loc[(data[date_col] >= test_start) & (data[date_col] <= test_end)]\n",
    "\n",
    "        if len(train_data) == 0 or len(val_data) == 0 or len(test_data) == 0:\n",
    "            print(f\"Fenêtre {start_date.year}-{test_end.year} : données insuffisantes, sautée.\")\n",
    "            start_date += relativedelta(years=1)\n",
    "            continue\n",
    "\n",
    "        # Configurer et entraîner AutoML\n",
    "        print(f\"Fenêtre {start_date.year}-{test_end.year} : entraînement de AutoML...\")\n",
    "        automl = AutoML(mode=\"Perform\", algorithms=[\"Xgboost\"])\n",
    "        custom_cv = [(train_data.index, val_data.index)]\n",
    "        automl.fit(\n",
    "            train_data.drop(columns=[target_col, date_col]),\n",
    "            train_data[target_col], cv=custom_cv\n",
    "        )\n",
    "\n",
    "        # Prédire sur le test set\n",
    "        test_preds = test_data[[date_col, target_col]].copy()\n",
    "        test_preds[\"predicted\"] = automl.predict(test_data.drop(columns=[target_col, date_col]))\n",
    "        test_preds[\"window\"] = f\"{start_date.year}-{test_end.year}\"\n",
    "\n",
    "        # Ajouter les périodes pour validation\n",
    "        test_preds[\"train_start\"] = start_date\n",
    "        test_preds[\"train_end\"] = train_end\n",
    "        test_preds[\"tampon_1\"] = tampon_1_end\n",
    "        test_preds[\"val_start\"] = val_start\n",
    "        test_preds[\"val_end\"] = val_end\n",
    "        test_preds[\"tampon_2\"] = tampon_2_end\n",
    "        test_preds[\"test_start\"] = test_start\n",
    "        test_preds[\"test_end\"] = test_end\n",
    "\n",
    "        # Sauvegarder les prédictions\n",
    "        predictions_all.append(test_preds)\n",
    "\n",
    "        # Avancer la fenêtre\n",
    "        start_date += relativedelta(years=1)\n",
    "\n",
    "    predictions_df = pd.concat(predictions_all, ignore_index=True)\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fenêtre 2015-2019 : entraînement de AutoML...\n",
      "AutoML directory: AutoML_8\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.670802 trained in 1.97 seconds (1-sample predict time 0.0071 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.66521 trained in 1.33 seconds (1-sample predict time 0.0071 seconds)\n",
      "3_Xgboost logloss 0.673821 trained in 1.55 seconds (1-sample predict time 0.0067 seconds)\n",
      "4_Xgboost logloss 0.691386 trained in 1.18 seconds (1-sample predict time 0.0074 seconds)\n",
      "5_Xgboost logloss 0.691386 trained in 1.15 seconds (1-sample predict time 0.007 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_sum_price_close_usd\n",
      "Add Golden Feature: trading_volume_sum_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_price_close_usd\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_sum_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_trading_volume\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "2_Xgboost_GoldenFeatures logloss 0.668285 trained in 1.83 seconds (1-sample predict time 0.0175 seconds)\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.677146 trained in 1.91 seconds (1-sample predict time 0.0175 seconds)\n",
      "3_Xgboost_GoldenFeatures logloss 0.676053 trained in 1.91 seconds (1-sample predict time 0.0183 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "2_Xgboost_RandomFeature logloss 0.663092 trained in 1.64 seconds (1-sample predict time 0.0077 seconds)\n",
      "Drop features ['random_feature', 'price_close_usd', 'sid']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "2_Xgboost_SelectedFeatures logloss 0.648154 trained in 1.97 seconds (1-sample predict time 0.0063 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_SelectedFeatures logloss 0.648309 trained in 2.12 seconds (1-sample predict time 0.0073 seconds)\n",
      "7_Xgboost_SelectedFeatures logloss 0.648361 trained in 1.89 seconds (1-sample predict time 0.0064 seconds)\n",
      "8_Xgboost logloss 0.665126 trained in 1.83 seconds (1-sample predict time 0.0066 seconds)\n",
      "9_Xgboost logloss 0.665459 trained in 1.8 seconds (1-sample predict time 0.0067 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_SelectedFeatures logloss 0.640808 trained in 1.99 seconds (1-sample predict time 0.0067 seconds)\n",
      "11_Xgboost_SelectedFeatures logloss 0.642017 trained in 2.25 seconds (1-sample predict time 0.0068 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.640808 trained in 0.9 seconds (1-sample predict time 0.0067 seconds)\n",
      "AutoML fit time: 38.9 seconds\n",
      "AutoML best model: 10_Xgboost_SelectedFeatures\n",
      "Fenêtre 2016-2020 : entraînement de AutoML...\n",
      "AutoML directory: AutoML_9\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.671811 trained in 1.93 seconds (1-sample predict time 0.0064 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.683018 trained in 1.28 seconds (1-sample predict time 0.0065 seconds)\n",
      "3_Xgboost logloss 0.673216 trained in 1.59 seconds (1-sample predict time 0.0071 seconds)\n",
      "4_Xgboost logloss 0.691386 trained in 0.99 seconds (1-sample predict time 0.0064 seconds)\n",
      "5_Xgboost logloss 0.691386 trained in 1.04 seconds (1-sample predict time 0.0067 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: trading_volume_sum_price_close_usd\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Add Golden Feature: market_cap_usd_ratio_price_close_usd\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: trading_volume_sum_market_cap_usd\n",
      "Add Golden Feature: trading_volume_ratio_price_close_usd\n",
      "Add Golden Feature: market_cap_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_ratio_market_cap_usd\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.687383 trained in 1.79 seconds (1-sample predict time 0.017 seconds)\n",
      "3_Xgboost_GoldenFeatures logloss 0.689085 trained in 1.83 seconds (1-sample predict time 0.0183 seconds)\n",
      "2_Xgboost_GoldenFeatures logloss 0.67453 trained in 2.07 seconds (1-sample predict time 0.0178 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "1_Default_Xgboost_RandomFeature logloss 0.666928 trained in 1.86 seconds (1-sample predict time 0.0078 seconds)\n",
      "Drop features ['random_feature', 'trading_volume', 'sid', 'price_close_usd']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "1_Default_Xgboost_SelectedFeatures logloss 0.633281 trained in 3.01 seconds (1-sample predict time 0.0065 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_SelectedFeatures logloss 0.632324 trained in 3.44 seconds (1-sample predict time 0.0069 seconds)\n",
      "7_Xgboost_SelectedFeatures logloss 0.632812 trained in 3.01 seconds (1-sample predict time 0.0062 seconds)\n",
      "8_Xgboost logloss 0.676106 trained in 2.11 seconds (1-sample predict time 0.0069 seconds)\n",
      "9_Xgboost logloss 0.673216 trained in 2.07 seconds (1-sample predict time 0.0065 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_SelectedFeatures logloss 0.632324 trained in 4.3 seconds (1-sample predict time 0.0061 seconds)\n",
      "11_Xgboost_SelectedFeatures logloss 0.632812 trained in 3.19 seconds (1-sample predict time 0.0064 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.627321 trained in 0.88 seconds (1-sample predict time 0.03 seconds)\n",
      "AutoML fit time: 46.46 seconds\n",
      "AutoML best model: Ensemble\n",
      "      window train_start  train_end  val_start    val_end test_start  \\\n",
      "0  2015-2019  2015-03-31 2017-03-30 2017-05-31 2018-05-30 2018-07-31   \n",
      "1  2015-2019  2015-03-31 2017-03-30 2017-05-31 2018-05-30 2018-07-31   \n",
      "2  2015-2019  2015-03-31 2017-03-30 2017-05-31 2018-05-30 2018-07-31   \n",
      "3  2015-2019  2015-03-31 2017-03-30 2017-05-31 2018-05-30 2018-07-31   \n",
      "4  2015-2019  2015-03-31 2017-03-30 2017-05-31 2018-05-30 2018-07-31   \n",
      "\n",
      "    test_end  \n",
      "0 2019-07-30  \n",
      "1 2019-07-30  \n",
      "2 2019-07-30  \n",
      "3 2019-07-30  \n",
      "4 2019-07-30  \n"
     ]
    }
   ],
   "source": [
    "predictions_df = pipeline_rolling_windows(\n",
    "    data=df_random, \n",
    "    date_col=\"date\", \n",
    "    target_col=\"target\", \n",
    "    train_years=2, \n",
    "    val_years=1, \n",
    "    test_years=1, \n",
    "    buffer_months=2\n",
    ")\n",
    "\n",
    "# Affiche un aperçu des périodes\n",
    "print(predictions_df[[\"window\", \"train_start\", \"train_end\", \"val_start\", \"val_end\", \"test_start\", \"test_end\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "      <th>window</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>tampon_1</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>tampon_2</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2019-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2019-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2019-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2019-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2019-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2020</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2020</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2020</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-2020</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2020</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  target  predicted     window train_start  train_end   tampon_1  \\\n",
       "0  2018-09-30       1          1  2015-2019  2015-03-31 2017-03-30 2017-05-30   \n",
       "1  2018-12-31       0          1  2015-2019  2015-03-31 2017-03-30 2017-05-30   \n",
       "2  2019-03-31       0          0  2015-2019  2015-03-31 2017-03-30 2017-05-30   \n",
       "3  2019-06-30       0          1  2015-2019  2015-03-31 2017-03-30 2017-05-30   \n",
       "4  2018-09-30       1          0  2015-2019  2015-03-31 2017-03-30 2017-05-30   \n",
       "..        ...     ...        ...        ...         ...        ...        ...   \n",
       "75 2020-06-30       1          0  2016-2020  2016-03-31 2018-03-30 2018-05-30   \n",
       "76 2019-09-30       1          0  2016-2020  2016-03-31 2018-03-30 2018-05-30   \n",
       "77 2019-12-31       1          0  2016-2020  2016-03-31 2018-03-30 2018-05-30   \n",
       "78 2020-03-31       1          1  2016-2020  2016-03-31 2018-03-30 2018-05-30   \n",
       "79 2020-06-30       1          0  2016-2020  2016-03-31 2018-03-30 2018-05-30   \n",
       "\n",
       "    val_start    val_end   tampon_2 test_start   test_end  \n",
       "0  2017-05-31 2018-05-30 2018-07-30 2018-07-31 2019-07-30  \n",
       "1  2017-05-31 2018-05-30 2018-07-30 2018-07-31 2019-07-30  \n",
       "2  2017-05-31 2018-05-30 2018-07-30 2018-07-31 2019-07-30  \n",
       "3  2017-05-31 2018-05-30 2018-07-30 2018-07-31 2019-07-30  \n",
       "4  2017-05-31 2018-05-30 2018-07-30 2018-07-31 2019-07-30  \n",
       "..        ...        ...        ...        ...        ...  \n",
       "75 2018-05-31 2019-05-30 2019-07-30 2019-07-31 2020-07-30  \n",
       "76 2018-05-31 2019-05-30 2019-07-30 2019-07-31 2020-07-30  \n",
       "77 2018-05-31 2019-05-30 2019-07-30 2019-07-31 2020-07-30  \n",
       "78 2018-05-31 2019-05-30 2019-07-30 2019-07-31 2020-07-30  \n",
       "79 2018-05-31 2019-05-30 2019-07-30 2019-07-31 2020-07-30  \n",
       "\n",
       "[80 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HECFinance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
