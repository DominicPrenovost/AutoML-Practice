{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from supervised.automl import AutoML\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_4826/963998424.py:9: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sid</th>\n",
       "      <th>market_cap_usd</th>\n",
       "      <th>price_close_usd</th>\n",
       "      <th>trading_volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>4148.729684</td>\n",
       "      <td>272.908820</td>\n",
       "      <td>43949.779527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>100.688595</td>\n",
       "      <td>66.082892</td>\n",
       "      <td>30598.580427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>6095.174361</td>\n",
       "      <td>338.372900</td>\n",
       "      <td>91240.908293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>9256.329320</td>\n",
       "      <td>275.487674</td>\n",
       "      <td>79261.468646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>4170.560452</td>\n",
       "      <td>175.532574</td>\n",
       "      <td>40081.561634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       sid  market_cap_usd  price_close_usd  trading_volume  \\\n",
       "0 2015-03-31  SID-0000     4148.729684       272.908820    43949.779527   \n",
       "1 2015-06-30  SID-0000      100.688595        66.082892    30598.580427   \n",
       "2 2015-09-30  SID-0000     6095.174361       338.372900    91240.908293   \n",
       "3 2015-12-31  SID-0000     9256.329320       275.487674    79261.468646   \n",
       "4 2016-03-31  SID-0000     4170.560452       175.532574    40081.561634   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_dataset(n_actions=50, start_date=\"2010-01-01\", end_date=\"2020-12-31\"):\n",
    "    \"\"\"\n",
    "    Génère un DataFrame fictif avec des données temporelles pour plusieurs actions.\n",
    "    - n_actions : nombre d'actions uniques (identifiants `sid`).\n",
    "    - start_date : date de début.\n",
    "    - end_date : date de fin.\n",
    "    \"\"\"\n",
    "    # Générer une plage de dates quotidienne\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=\"Q\")  # Fréquence trimestrielle\n",
    "    \n",
    "    # Générer des identifiants pour les actions\n",
    "    sids = [f\"SID-{i:04d}\" for i in range(n_actions)]\n",
    "    \n",
    "    # Liste pour stocker les données\n",
    "    data = []\n",
    "    \n",
    "    for sid in sids:\n",
    "        for date in date_range:\n",
    "            # Générer des valeurs aléatoires pour les variables explicatives et la cible\n",
    "            market_cap_usd = np.random.uniform(100, 10000)  # Capitalisation aléatoire\n",
    "            price_close_usd = np.random.uniform(10, 500)    # Prix de clôture\n",
    "            trading_volume = np.random.uniform(1000, 100000)  # Volume de trading\n",
    "            target = np.random.choice([0, 1])  # Variable cible (0 ou 1)\n",
    "            \n",
    "            # Ajouter la ligne au dataset\n",
    "            data.append([date, sid, market_cap_usd, price_close_usd, trading_volume, target])\n",
    "    \n",
    "    # Convertir en DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"date\", \"sid\", \"market_cap_usd\", \"price_close_usd\", \"trading_volume\", \"target\"])\n",
    "    return df\n",
    "\n",
    "# Générer un dataset fictif\n",
    "df_random = generate_random_dataset(n_actions=10, start_date=\"2015-01-01\", end_date=\"2020-12-31\")\n",
    "\n",
    "# Afficher un aperçu\n",
    "df_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rolling_windows(data, date_col, target_col, train_years, val_years, test_years, buffer_months):\n",
    "    \"\"\"\n",
    "    Pipeline direct pour la rolling window avec AutoML.\n",
    "    \"\"\"\n",
    "    data[date_col] = pd.to_datetime(data[date_col])  # Assurer le bon format de date\n",
    "    start_date = data[date_col].min()\n",
    "    end_date = data[date_col].max()\n",
    "\n",
    "    predictions_all = []  # Liste pour stocker toutes les prédictions\n",
    "\n",
    "    while start_date + relativedelta(years=train_years + val_years + test_years) <= end_date:\n",
    "        # Définir les périodes\n",
    "        train_end = start_date + relativedelta(years=train_years) - pd.Timedelta(days=1)\n",
    "        tampon_1_start = train_end + pd.Timedelta(days=1)\n",
    "        tampon_1_end = tampon_1_start + relativedelta(months=buffer_months) - pd.Timedelta(days=1)\n",
    "        val_start = tampon_1_end + pd.Timedelta(days=1)\n",
    "        val_end = val_start + relativedelta(years=val_years) - pd.Timedelta(days=1)\n",
    "        tampon_2_start = val_end + pd.Timedelta(days=1)\n",
    "        tampon_2_end = tampon_2_start + relativedelta(months=buffer_months) - pd.Timedelta(days=1)\n",
    "        test_start = tampon_2_end + pd.Timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=test_years) - pd.Timedelta(days=1)\n",
    "\n",
    "        # Filtrer les données pour chaque période\n",
    "        train_data = data.loc[(data[date_col] >= start_date) & (data[date_col] <= train_end)]\n",
    "        val_data = data.loc[(data[date_col] >= val_start) & (data[date_col] <= val_end)]\n",
    "        test_data = data.loc[(data[date_col] >= test_start) & (data[date_col] <= test_end)]\n",
    "\n",
    "        # Configurer et entraîner AutoML\n",
    "        automl = AutoML(mode=\"Perform\", algorithms=[\"Xgboost\"])\n",
    "        automl.fit(\n",
    "            train_data.drop(columns=[target_col, date_col]),\n",
    "            train_data[target_col]\n",
    "        )\n",
    "\n",
    "        # Prédire sur le test set\n",
    "        test_preds = test_data[[date_col, target_col]].copy()\n",
    "        test_preds[\"predicted\"] = automl.predict(test_data.drop(columns=[target_col, date_col]))\n",
    "        test_preds[\"window\"] = f\"{start_date.year}-{test_end.year}\"  # Identifier la fenêtre\n",
    "\n",
    "        # Sauvegarder les prédictions\n",
    "        predictions_all.append(test_preds)\n",
    "\n",
    "        # Avancer la fenêtre\n",
    "        start_date += relativedelta(years=1)\n",
    "\n",
    "    # Concaténer toutes les prédictions\n",
    "    predictions_df = pd.concat(predictions_all, ignore_index=True)\n",
    "\n",
    "    return print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_1\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.690826 trained in 6.88 seconds (1-sample predict time 0.0069 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.691655 trained in 3.56 seconds (1-sample predict time 0.0063 seconds)\n",
      "3_Xgboost logloss 0.692445 trained in 1.49 seconds (1-sample predict time 0.0066 seconds)\n",
      "4_Xgboost logloss 0.693538 trained in 1.14 seconds (1-sample predict time 0.0063 seconds)\n",
      "5_Xgboost logloss 0.693538 trained in 2.33 seconds (1-sample predict time 0.0073 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_price_close_usd\n",
      "Add Golden Feature: price_close_usd_multiply_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_price_close_usd\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_ratio_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_sum_market_cap_usd\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.677996 trained in 1.71 seconds (1-sample predict time 0.0177 seconds)\n",
      "2_Xgboost_GoldenFeatures logloss 0.686367 trained in 1.57 seconds (1-sample predict time 0.0169 seconds)\n",
      "3_Xgboost_GoldenFeatures logloss 0.682088 trained in 1.82 seconds (1-sample predict time 0.0167 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "1_Default_Xgboost_GoldenFeatures_RandomFeature logloss 0.693497 trained in 1.92 seconds (1-sample predict time 0.0182 seconds)\n",
      "Drop features ['price_close_usd_multiply_market_cap_usd', 'random_feature', 'price_close_usd', 'price_close_usd_ratio_market_cap_usd', 'market_cap_usd_diff_trading_volume', 'market_cap_usd_ratio_price_close_usd', 'price_close_usd_diff_trading_volume', 'trading_volume_ratio_market_cap_usd', 'market_cap_usd_ratio_trading_volume', 'sid', 'trading_volume', 'price_close_usd_sum_market_cap_usd', 'market_cap_usd_diff_price_close_usd']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "1_Default_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.699886 trained in 1.76 seconds (1-sample predict time 0.0114 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_GoldenFeatures logloss 0.678773 trained in 2.01 seconds (1-sample predict time 0.0178 seconds)\n",
      "7_Xgboost_GoldenFeatures logloss 0.678672 trained in 2.02 seconds (1-sample predict time 0.0174 seconds)\n",
      "8_Xgboost_GoldenFeatures logloss 0.678146 trained in 2.07 seconds (1-sample predict time 0.0175 seconds)\n",
      "9_Xgboost_GoldenFeatures logloss 0.684146 trained in 2.03 seconds (1-sample predict time 0.0174 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_GoldenFeatures logloss 0.675155 trained in 2.14 seconds (1-sample predict time 0.0175 seconds)\n",
      "11_Xgboost_GoldenFeatures logloss 0.677555 trained in 2.26 seconds (1-sample predict time 0.0177 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.675155 trained in 0.87 seconds (1-sample predict time 0.018 seconds)\n",
      "AutoML fit time: 47.89 seconds\n",
      "AutoML best model: 10_Xgboost_GoldenFeatures\n",
      "AutoML directory: AutoML_2\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.696817 trained in 1.85 seconds (1-sample predict time 0.0069 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.695306 trained in 1.28 seconds (1-sample predict time 0.0066 seconds)\n",
      "3_Xgboost logloss 0.696637 trained in 1.6 seconds (1-sample predict time 0.0065 seconds)\n",
      "4_Xgboost logloss 0.693538 trained in 1.14 seconds (1-sample predict time 0.0063 seconds)\n",
      "5_Xgboost logloss 0.693538 trained in 1.17 seconds (1-sample predict time 0.0068 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: price_close_usd_sum_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_ratio_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_price_close_usd\n",
      "Add Golden Feature: price_close_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_ratio_price_close_usd\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_price_close_usd\n",
      "Add Golden Feature: price_close_usd_multiply_market_cap_usd\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "4_Xgboost_GoldenFeatures logloss 0.693538 trained in 1.32 seconds (1-sample predict time 0.0168 seconds)\n",
      "5_Xgboost_GoldenFeatures logloss 0.693538 trained in 1.37 seconds (1-sample predict time 0.018 seconds)\n",
      "2_Xgboost_GoldenFeatures logloss 0.678113 trained in 1.62 seconds (1-sample predict time 0.0177 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "2_Xgboost_GoldenFeatures_RandomFeature logloss 0.658902 trained in 1.75 seconds (1-sample predict time 0.0187 seconds)\n",
      "Drop features ['random_feature', 'trading_volume_multiply_market_cap_usd', 'market_cap_usd', 'market_cap_usd_ratio_trading_volume', 'trading_volume_ratio_market_cap_usd', 'trading_volume_ratio_price_close_usd', 'market_cap_usd_diff_trading_volume', 'price_close_usd_multiply_market_cap_usd', 'market_cap_usd_diff_price_close_usd', 'trading_volume', 'sid', 'price_close_usd_sum_market_cap_usd', 'price_close_usd_ratio_trading_volume', 'price_close_usd']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "2_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.670934 trained in 1.57 seconds (1-sample predict time 0.0101 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.671044 trained in 1.68 seconds (1-sample predict time 0.0103 seconds)\n",
      "7_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.666411 trained in 2.11 seconds (1-sample predict time 0.0098 seconds)\n",
      "8_Xgboost_GoldenFeatures logloss 0.679037 trained in 1.85 seconds (1-sample predict time 0.0186 seconds)\n",
      "9_Xgboost_GoldenFeatures logloss 0.678788 trained in 1.85 seconds (1-sample predict time 0.0183 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.666411 trained in 2.26 seconds (1-sample predict time 0.0105 seconds)\n",
      "11_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.670934 trained in 1.82 seconds (1-sample predict time 0.0103 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.666222 trained in 0.89 seconds (1-sample predict time 0.0174 seconds)\n",
      "AutoML fit time: 37.2 seconds\n",
      "AutoML best model: 2_Xgboost_GoldenFeatures_RandomFeature\n",
      "         date  target  predicted     window\n",
      "0  2018-06-30       0          0  2015-2019\n",
      "1  2018-09-30       1          0  2015-2019\n",
      "2  2018-12-31       0          0  2015-2019\n",
      "3  2019-03-31       0          0  2015-2019\n",
      "4  2018-06-30       1          0  2015-2019\n",
      "..        ...     ...        ...        ...\n",
      "75 2020-03-31       1          0  2016-2020\n",
      "76 2019-06-30       0          0  2016-2020\n",
      "77 2019-09-30       1          0  2016-2020\n",
      "78 2019-12-31       0          1  2016-2020\n",
      "79 2020-03-31       1          0  2016-2020\n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline_rolling_windows(\n",
    "    data=df_random,\n",
    "    date_col=\"date\",\n",
    "    target_col=\"target\",\n",
    "    train_years=2,\n",
    "    val_years=1,\n",
    "    test_years=1,\n",
    "    buffer_months=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HECFinance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
