{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from supervised.automl import AutoML\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>QUALITY_FLAG</th>\n",
       "      <th>cid</th>\n",
       "      <th>industry_raw</th>\n",
       "      <th>E_TTM_period_date</th>\n",
       "      <th>E_TTM_ammor_intangibles</th>\n",
       "      <th>E_TTM_asset_writedown</th>\n",
       "      <th>E_TTM_assets_gro_five</th>\n",
       "      <th>E_TTM_capex</th>\n",
       "      <th>E_TTM_cash_acquisitions</th>\n",
       "      <th>...</th>\n",
       "      <th>E_G_ebitda_cov</th>\n",
       "      <th>E_G_ret_on_asset</th>\n",
       "      <th>E_G_ret_on_inv_cap</th>\n",
       "      <th>E_G_net_to_cash</th>\n",
       "      <th>E_G_perm_assets_ratio</th>\n",
       "      <th>return_1q</th>\n",
       "      <th>target_net_income</th>\n",
       "      <th>target_cash_operations</th>\n",
       "      <th>binary_target_net_income</th>\n",
       "      <th>binary_target_cash_operations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-03</td>\n",
       "      <td>True</td>\n",
       "      <td>SP-065996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-10-31</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.738000</td>\n",
       "      <td>-3.336</td>\n",
       "      <td>...</td>\n",
       "      <td>-165.453488</td>\n",
       "      <td>0.130018</td>\n",
       "      <td>0.101871</td>\n",
       "      <td>-0.068216</td>\n",
       "      <td>0.414230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>SP-002396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-09-30</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.889000</td>\n",
       "      <td>-68.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.685925</td>\n",
       "      <td>0.071119</td>\n",
       "      <td>0.067430</td>\n",
       "      <td>-0.004881</td>\n",
       "      <td>0.595752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>SP-006704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-09-30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.971623</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.262460</td>\n",
       "      <td>-0.069781</td>\n",
       "      <td>-0.039238</td>\n",
       "      <td>-0.045993</td>\n",
       "      <td>0.775432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>SP-008644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-09-30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.700000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852273</td>\n",
       "      <td>-0.169833</td>\n",
       "      <td>-0.155712</td>\n",
       "      <td>-0.316372</td>\n",
       "      <td>0.773996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>SP-013994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-09-30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1403.000000</td>\n",
       "      <td>-133.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.569697</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>0.078497</td>\n",
       "      <td>-0.157934</td>\n",
       "      <td>0.921832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  QUALITY_FLAG        cid industry_raw E_TTM_period_date  \\\n",
       "0  2002-01-03          True  SP-065996          NaN        2001-10-31   \n",
       "1  2002-01-08          True  SP-002396          NaN        2001-09-30   \n",
       "2  2002-01-08          True  SP-006704          NaN        2001-09-30   \n",
       "3  2002-01-08          True  SP-008644          NaN        2001-09-30   \n",
       "4  2002-01-08          True  SP-013994          NaN        2001-09-30   \n",
       "\n",
       "   E_TTM_ammor_intangibles  E_TTM_asset_writedown  E_TTM_assets_gro_five  \\\n",
       "0                    0.000                    0.0                    0.0   \n",
       "1                    3.078                    0.0                    0.0   \n",
       "2                    0.000                    0.0                    0.0   \n",
       "3                    0.000                    0.0                    0.0   \n",
       "4                    0.000                    0.0                    0.0   \n",
       "\n",
       "   E_TTM_capex  E_TTM_cash_acquisitions  ...  E_G_ebitda_cov  \\\n",
       "0   -12.738000                   -3.336  ...     -165.453488   \n",
       "1   -20.889000                  -68.220  ...       -2.685925   \n",
       "2   -17.971623                    0.000  ...        2.262460   \n",
       "3   -34.700000                    0.000  ...       -4.852273   \n",
       "4 -1403.000000                 -133.000  ...      -14.569697   \n",
       "\n",
       "   E_G_ret_on_asset  E_G_ret_on_inv_cap  E_G_net_to_cash  \\\n",
       "0          0.130018            0.101871        -0.068216   \n",
       "1          0.071119            0.067430        -0.004881   \n",
       "2         -0.069781           -0.039238        -0.045993   \n",
       "3         -0.169833           -0.155712        -0.316372   \n",
       "4          0.109798            0.078497        -0.157934   \n",
       "\n",
       "   E_G_perm_assets_ratio  return_1q  target_net_income  \\\n",
       "0               0.414230        NaN                NaN   \n",
       "1               0.595752        NaN                NaN   \n",
       "2               0.775432        NaN                NaN   \n",
       "3               0.773996        NaN                NaN   \n",
       "4               0.921832        NaN                NaN   \n",
       "\n",
       "   target_cash_operations  binary_target_net_income  \\\n",
       "0                     NaN                         0   \n",
       "1                     NaN                         0   \n",
       "2                     NaN                         0   \n",
       "3                     NaN                         0   \n",
       "4                     NaN                         0   \n",
       "\n",
       "   binary_target_cash_operations  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 670 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_canada = pd.read_csv('canada_updated.csv')\n",
    "df_canada.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_canada.copy()\n",
    "\n",
    "df_model['date'] = pd.to_datetime(df_model['date'], errors='coerce')\n",
    "df_model.sort_values(by=['cid', 'date'], inplace=True)\n",
    "\n",
    "# Retirer les lignes où Quality_Flag est False\n",
    "df_model = df_model[df_model['QUALITY_FLAG'] == True]\n",
    "\n",
    "# (FACULTATIF) Exclure les banques\n",
    "# df_model = df_model[df_model['industry'] != 'Banks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(\n",
    "    df,\n",
    "    include_agro=False,\n",
    "    include_rgro=False,\n",
    "    include_tcgro=False,\n",
    "    include_ratios_assets=False,\n",
    "    include_ratios_rev=False,\n",
    "    include_ratios_totcap=False,\n",
    "    mandatory_cols=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Sélectionne dynamiquement les colonnes d'un DataFrame en fonction\n",
    "    des familles de variables explicatives demandées,\n",
    "    en plaçant d'abord les colonnes obligatoires (mandatory_cols).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Gérer la liste mandatory_cols (par défaut : vide ou ['cid','date'] selon besoin)\n",
    "    if mandatory_cols is None:\n",
    "        mandatory_cols = []\n",
    "    \n",
    "    # 2) Définir les \"familles\" de motifs\n",
    "    family_patterns = {\n",
    "        'agro': ['_agro_1q', '_agro_4q'],\n",
    "        'rgro': ['_rgro_1q', '_rgro_4q'],\n",
    "        'tcgro': ['_tcgro_1q', '_tcgro_4q'],\n",
    "        'ratios_assets': ['_on_assets_ratio'],\n",
    "        'ratios_rev': ['_on_rev_ratio'],\n",
    "        'ratios_totcap': ['_on_tot_cap_ratio']\n",
    "    }\n",
    "    \n",
    "    # 3) Construire la liste des motifs à inclure\n",
    "    patterns_to_keep = []\n",
    "    if include_agro:\n",
    "        patterns_to_keep += family_patterns['agro']\n",
    "    if include_rgro:\n",
    "        patterns_to_keep += family_patterns['rgro']\n",
    "    if include_tcgro:\n",
    "        patterns_to_keep += family_patterns['tcgro']\n",
    "    \n",
    "    if include_ratios_assets:\n",
    "        patterns_to_keep += family_patterns['ratios_assets']\n",
    "    if include_ratios_rev:\n",
    "        patterns_to_keep += family_patterns['ratios_rev']\n",
    "    if include_ratios_totcap:\n",
    "        patterns_to_keep += family_patterns['ratios_totcap']\n",
    "    \n",
    "    # 4) Retrouver toutes les colonnes du df qui matchent nos motifs\n",
    "    matched_cols = set()\n",
    "    for pat in patterns_to_keep:\n",
    "        for col in df.columns:\n",
    "            if pat in col:\n",
    "                matched_cols.add(col)\n",
    "    # => matched_cols est un set() de colonnes\n",
    "    \n",
    "    # 5) Conserver l'ordre original des colonnes matched, \n",
    "    #    en filtrant df.columns dans l'ordre d'origine\n",
    "    matched_cols_in_order = [c for c in df.columns if c in matched_cols]\n",
    "    \n",
    "    # 6) Construire l'ordre final :\n",
    "    #    - d'abord mandatory_cols (dans l'ordre donné),\n",
    "    #    - puis les matched_cols (dans l'ordre d'origine)\n",
    "    #    - attention aux colonnes obligatoires qui n'existent pas, \n",
    "    #      ou aux duplications\n",
    "    #    - on fait donc une intersection + un set() pour éviter \n",
    "    #      les collisions.\n",
    "    \n",
    "    # Intersection pour ne pas inclure des mandatory inexistantes\n",
    "    mandatory_cols_in_df = [c for c in mandatory_cols if c in df.columns]\n",
    "    \n",
    "    # Puis on concatène en évitant toute duplication\n",
    "    columns_to_keep_ordered = mandatory_cols_in_df + [\n",
    "        c for c in matched_cols_in_order if c not in mandatory_cols_in_df\n",
    "    ]\n",
    "    \n",
    "    # 7) Extraire le sous-DataFrame\n",
    "    df_filtered = df[columns_to_keep_ordered].copy()\n",
    "    \n",
    "    # 8) (Optionnel) trier par cid/date si elles sont présentes\n",
    "    if 'cid' in df_filtered.columns and 'date' in df_filtered.columns:\n",
    "        df_filtered.sort_values(by=['cid', 'date'], inplace=True)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de valeurs NaN dans df_model_final : 443777\n",
      "Nombre total de valeurs NaN après suppression : 0\n"
     ]
    }
   ],
   "source": [
    "df_model_final = select_features(\n",
    "    df_model,\n",
    "    include_agro=True,          # inclut _agro_1q, _agro_4q\n",
    "    include_ratios_assets=True, # inclut _on_assets_ratio\n",
    "    mandatory_cols=['cid', 'date', 'binary_target_net_income']  # je garde la target\n",
    ")\n",
    "\n",
    "# Compter le nombre total de NaN dans tout le DataFrame\n",
    "total_nan = df_model_final.isna().sum().sum()\n",
    "print(f\"Nombre total de valeurs NaN dans df_model_final : {total_nan}\")\n",
    "\n",
    "# Retirer les lignes qui contiennent AU MOINS un NaN\n",
    "df_model_final.dropna(inplace=True)\n",
    "\n",
    "# Vérifier à nouveau qu’il n’y a plus de NaN\n",
    "total_nan_apres = df_model_final.isna().sum().sum()\n",
    "print(f\"Nombre total de valeurs NaN après suppression : {total_nan_apres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de valeurs NaN dans df_model_final : 1360861\n",
      "Nombre total de valeurs NaN après suppression : 0\n",
      "(36154, 579)\n"
     ]
    }
   ],
   "source": [
    "df_model_final = select_features(\n",
    "    df_model,\n",
    "    include_agro=True,\n",
    "    include_rgro=True,\n",
    "    include_tcgro=True,\n",
    "    include_ratios_assets=True,\n",
    "    include_ratios_rev=True,\n",
    "    include_ratios_totcap=True,\n",
    "    mandatory_cols=['cid', 'date', 'binary_target_net_income']  # je garde la target\n",
    ")\n",
    "\n",
    "# Compter le nombre total de NaN dans tout le DataFrame\n",
    "total_nan = df_model_final.isna().sum().sum()\n",
    "print(f\"Nombre total de valeurs NaN dans df_model_final : {total_nan}\")\n",
    "\n",
    "# Retirer les lignes qui contiennent AU MOINS un NaN\n",
    "df_model_final.dropna(inplace=True)\n",
    "\n",
    "# Vérifier à nouveau qu’il n’y a plus de NaN\n",
    "total_nan_apres = df_model_final.isna().sum().sum()\n",
    "print(f\"Nombre total de valeurs NaN après suppression : {total_nan_apres}\")\n",
    "\n",
    "print(df_model_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-12 00:00:00 2024-12-12 00:00:00\n",
      "(7552, 195)\n"
     ]
    }
   ],
   "source": [
    "# Date la plus récente du DataFrame\n",
    "max_date = df_model_final['date'].max()\n",
    "\n",
    "# Date de coupure (5 ans avant)\n",
    "cutoff_date = max_date - pd.DateOffset(years=5)\n",
    "\n",
    "# Filtrer pour ne garder que les 5 dernières années\n",
    "df_test = df_model_final[df_model_final['date'] >= cutoff_date].copy()\n",
    "\n",
    "print(df_test['date'].min(), df_test['date'].max())\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rolling_windows(data, date_col, target_col, train_years, val_years, test_years, buffer_months=0):\n",
    "    \"\"\"\n",
    "    Pipeline direct pour la rolling window avec AutoML et cross-validation personnalisée.\n",
    "    Ajoute les périodes dans le DataFrame final pour validation.\n",
    "    \"\"\"\n",
    "    # Conversion de la colonne date\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    start_date = data[date_col].min()\n",
    "    end_date = data[date_col].max()\n",
    "\n",
    "    predictions_all = []  # Liste pour stocker toutes les prédictions\n",
    "\n",
    "    while start_date + relativedelta(years=train_years + val_years + test_years) <= end_date:\n",
    "        # Définir les périodes\n",
    "        train_end = start_date + relativedelta(years=train_years) - pd.Timedelta(days=1)\n",
    "        tampon_1_end = train_end + relativedelta(months=buffer_months)\n",
    "        val_start = tampon_1_end + pd.Timedelta(days=1)\n",
    "        val_end = val_start + relativedelta(years=val_years) - pd.Timedelta(days=1)\n",
    "        tampon_2_end = val_end + relativedelta(months=buffer_months)\n",
    "        test_start = tampon_2_end + pd.Timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=test_years) - pd.Timedelta(days=1)\n",
    "\n",
    "        # Filtrer les données\n",
    "        train_data = data.loc[(data[date_col] >= start_date) & (data[date_col] <= train_end)]\n",
    "        val_data = data.loc[(data[date_col] >= val_start) & (data[date_col] <= val_end)]\n",
    "        test_data = data.loc[(data[date_col] >= test_start) & (data[date_col] <= test_end)]\n",
    "\n",
    "        if len(train_data) == 0 or len(val_data) == 0 or len(test_data) == 0:\n",
    "            print(f\"Fenêtre {start_date.year}-{test_end.year} : données insuffisantes, sautée.\")\n",
    "            start_date += relativedelta(years=1)\n",
    "            continue\n",
    "\n",
    "        # Configurer et entraîner AutoML\n",
    "        print(f\"Fenêtre {start_date.year}-{test_end.year} : entraînement de AutoML...\")\n",
    "        automl = AutoML(mode=\"Perform\", algorithms=[\"Xgboost\"], eval_metric=\"auc\")\n",
    "        custom_cv = [(train_data.index, val_data.index)]\n",
    "        automl.fit(\n",
    "            train_data.drop(columns=[target_col, date_col, 'cid']),\n",
    "            train_data[target_col], cv=custom_cv\n",
    "        )\n",
    "\n",
    "        # Prédire sur le test set\n",
    "        test_preds = test_data[[date_col, target_col]].copy()\n",
    "        #test_preds[\"predicted\"] = automl.predict_proba(test_data.drop(columns=[target_col, date_col, 'cid']))\n",
    "        proba = automl.predict_proba(test_data.drop(columns=[target_col, date_col, 'cid']))\n",
    "        test_preds[\"proba_class_0\"] = proba[:, 0]  # Probabilité pour la classe 0 (diminution des bénéfices)\n",
    "        test_preds[\"proba_class_1\"] = proba[:, 1]  # Probabilité pour la classe 1 (augmentation des bénéfices)\n",
    "        test_preds[\"margin_proba\"] = test_preds[\"proba_class_1\"] - test_preds[\"proba_class_0\"]\n",
    "        test_preds[\"window\"] = f\"{start_date.year}-{test_end.year}\"\n",
    "        test_preds[\"cid\"] = test_data[\"cid\"].values\n",
    "\n",
    "        # Ajouter les périodes pour validation\n",
    "        #test_preds[\"train_start\"] = start_date\n",
    "        #test_preds[\"train_end\"] = train_end\n",
    "        #test_preds[\"tampon_1\"] = tampon_1_end\n",
    "        #test_preds[\"val_start\"] = val_start\n",
    "        #test_preds[\"val_end\"] = val_end\n",
    "        #test_preds[\"tampon_2\"] = tampon_2_end\n",
    "        #test_preds[\"test_start\"] = test_start\n",
    "        #test_preds[\"test_end\"] = test_end\n",
    "\n",
    "        # Sauvegarder les prédictions\n",
    "        predictions_all.append(test_preds)\n",
    "\n",
    "        # Avancer la fenêtre\n",
    "        start_date += relativedelta(years=1)\n",
    "\n",
    "    predictions_df = pd.concat(predictions_all, ignore_index=True)\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fenêtre 2019-2024 : entraînement de AutoML...\n",
      "AutoML directory: AutoML_2\n",
      "The task is binary_classification with evaluation metric auc\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost auc 0.866391 trained in 18.94 seconds (1-sample predict time 0.035 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost auc 0.860464 trained in 14.29 seconds (1-sample predict time 0.0353 seconds)\n",
      "3_Xgboost auc 0.86656 trained in 15.04 seconds (1-sample predict time 0.0357 seconds)\n",
      "4_Xgboost auc 0.844248 trained in 15.99 seconds (1-sample predict time 0.0371 seconds)\n",
      "5_Xgboost auc 0.795209 trained in 8.78 seconds (1-sample predict time 0.0359 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 19\n",
      "Add Golden Feature: E_G_norm_net_inc_agro_1q_diff_E_G_net_income_inc_on_assets_ratio\n",
      "Add Golden Feature: E_G_norm_net_inc_on_assets_ratio_sum_E_G_retained_earnings_agro_4q\n",
      "Add Golden Feature: E_G_retained_earnings_agro_1q_diff_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_ebit_on_assets_ratio_sum_E_G_net_income_inc_agro_4q\n",
      "Add Golden Feature: E_G_cash_equi_on_assets_ratio_sum_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_depre_amor_on_assets_ratio_sum_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_total_debt_on_assets_ratio_ratio_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_total_liabilities_on_assets_ratio_multiply_E_G_net_income_inc_on_assets_ratio\n",
      "Add Golden Feature: E_G_net_income_inc_on_assets_ratio_diff_E_G_tax_expense_on_assets_ratio\n",
      "Add Golden Feature: E_G_total_div_on_assets_ratio_ratio_E_G_net_income_inc_on_assets_ratio\n",
      "Add Golden Feature: E_G_ebitda_on_assets_ratio_ratio_E_G_net_income_inc_on_assets_ratio\n",
      "Add Golden Feature: E_G_cash_investing_on_assets_ratio_sum_E_G_total_capital_agro_4q\n",
      "Add Golden Feature: E_G_net_income_inc_agro_4q_sum_E_G_current_liabilities_agro_1q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_sum_E_G_norm_net_inc_agro_1q\n",
      "Add Golden Feature: E_G_gross_property_agro_4q_sum_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_net_income_inc_on_assets_ratio_sum_E_G_ebit_agro_4q\n",
      "Add Golden Feature: E_G_net_income_inc_on_assets_ratio_sum_E_G_operating_income_agro_4q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_sum_E_G_other_expenses_agro_1q\n",
      "Add Golden Feature: E_G_tangible_book_agro_1q_diff_E_G_common_equity_agro_4q\n",
      "Created 19 Golden Features in 12.73 seconds.\n",
      "3_Xgboost_GoldenFeatures auc 0.86779 trained in 28.78 seconds (1-sample predict time 0.0602 seconds)\n",
      "1_Default_Xgboost_GoldenFeatures auc 0.863885 trained in 18.32 seconds (1-sample predict time 0.0599 seconds)\n",
      "2_Xgboost_GoldenFeatures auc 0.862694 trained in 15.76 seconds (1-sample predict time 0.06 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "3_Xgboost_GoldenFeatures_RandomFeature auc 0.869672 trained in 17.15 seconds (1-sample predict time 0.0572 seconds)\n",
      "Drop features ['E_G_net_income_inc_agro_4q', 'E_G_total_capital_on_assets_ratio', 'E_G_cost_borrowing_on_assets_ratio', 'E_G_total_debt_on_assets_ratio', 'E_G_def_tax_liability_agro_4q', 'E_G_interest_expense_agro_4q', 'E_G_total_liabilities_on_assets_ratio', 'E_G_payables_agro_4q', 'E_G_asset_writedown_on_assets_ratio', 'E_G_compre_income_agro_1q', 'E_G_current_assets_on_assets_ratio', 'E_G_receivables_on_assets_ratio', 'E_G_cash_financing_agro_4q', 'E_G_int_div_income_agro_4q', 'E_G_operating_income_on_assets_ratio', 'E_G_common_equity_agro_1q', 'E_G_restructuring_charges_on_assets_ratio', 'E_G_total_div_on_assets_ratio', 'E_G_cash_equi_agro_1q', 'E_G_ebitda_agro_1q', 'E_G_repurchase_stock_agro_1q', 'E_G_capex_on_assets_ratio', 'E_G_r_d_agro_4q', 'E_G_cost_borrowing_agro_1q', 'random_feature', 'E_G_ammor_intangibles_on_assets_ratio', 'E_G_total_revenues_on_assets_ratio', 'E_G_restructuring_charges_agro_1q', 'E_G_ebt_x_unusual_agro_1q', 'E_G_net_debt_on_assets_ratio', 'E_G_divestitures_agro_1q', 'E_G_sga_agro_1q', 'E_G_total_expenses_agro_1q', 'E_G_core_banks_agro_4q', 'E_G_inventory_agro_1q', 'E_G_core_banks_on_assets_ratio', 'E_G_minority_int_on_assets_ratio', 'E_G_r_d_agro_1q', 'E_G_depre_amor_on_assets_ratio_sum_E_G_common_equity_agro_4q', 'E_G_core_banks_agro_1q', 'E_G_total_expenses_agro_4q', 'E_G_pref_equity_agro_1q', 'E_G_provision_loan_agro_4q', 'E_G_total_assets_agro_1q', 'E_G_ebt_x_unusual_on_assets_ratio', 'E_G_pref_div_agro_4q', 'E_G_provision_loan_agro_1q', 'E_G_tax_expense_on_assets_ratio', 'E_G_pref_equity_agro_4q', 'E_G_total_intangibles_agro_1q', 'E_G_provision_loan_on_assets_ratio', 'E_G_net_inc_gro_five_agro_4q', 'E_G_pref_div_on_assets_ratio', 'E_G_total_debt_agro_4q', 'E_G_total_debt_on_assets_ratio_ratio_E_G_common_equity_agro_4q', 'E_G_common_equity_agro_4q_sum_E_G_norm_net_inc_agro_1q', 'E_G_quick_ratio_agro_4q', 'E_G_operating_income_agro_4q', 'E_G_net_inc_gro_five_on_assets_ratio', 'E_G_divestitures_on_assets_ratio', 'E_G_quick_ratio_agro_1q', 'E_G_inventory_agro_4q', 'E_G_common_equity_agro_4q_sum_E_G_other_expenses_agro_1q', 'E_G_unusual_items_agro_1q', 'E_G_def_tax_liability_agro_1q', 'E_G_ops_expenses_agro_1q', 'E_G_working_cap_agro_4q', 'E_G_minority_int_agro_4q', 'E_G_cash_acquisitions_agro_1q', 'E_G_tangible_book_agro_1q', 'E_G_net_inc_gro_five_agro_1q', 'E_G_cogs_agro_4q', 'E_G_cogs_agro_1q', 'E_G_ebit_on_assets_ratio', 'E_G_ops_expenses_on_assets_ratio', 'E_G_pref_div_agro_1q', 'E_G_cash_acquisitions_agro_4q', 'E_G_rev_gro_five_agro_1q', 'E_G_ebit_agro_4q', 'E_G_ebit_agro_1q', 'E_G_current_assets_agro_1q', 'E_G_ebit_on_assets_ratio_sum_E_G_net_income_inc_agro_4q', 'E_G_net_property_agro_1q', 'E_G_gross_profit_agro_4q', 'E_G_current_assets_agro_4q', 'E_G_cash_operations_agro_1q', 'E_G_gross_property_agro_1q', 'E_G_common_equity_agro_4q', 'E_G_total_debt_agro_1q', 'E_G_cash_investing_agro_1q', 'E_G_cash_financing_on_assets_ratio', 'E_G_working_cap_agro_1q', 'E_G_other_expenses_agro_1q', 'E_G_net_income_inc_agro_4q_sum_E_G_current_liabilities_agro_1q', 'E_G_net_income_inc_on_assets_ratio_sum_E_G_ebit_agro_4q', 'E_G_assets_gro_five_agro_1q', 'E_G_retained_earnings_agro_1q', 'E_G_norm_net_inc_on_assets_ratio_sum_E_G_retained_earnings_agro_4q', 'E_G_total_capital_agro_1q', 'E_G_operating_income_agro_1q', 'E_G_net_income_inc_on_assets_ratio_sum_E_G_operating_income_agro_4q', 'E_G_cash_equi_on_assets_ratio_sum_E_G_common_equity_agro_4q', 'E_G_total_capital_agro_4q', 'E_G_int_div_income_on_assets_ratio', 'E_G_payables_agro_1q', 'E_G_retained_earnings_agro_4q', 'E_G_cash_investing_on_assets_ratio_sum_E_G_total_capital_agro_4q', 'E_G_gross_property_agro_4q_sum_E_G_common_equity_agro_4q', 'E_G_retained_earnings_agro_1q_diff_E_G_common_equity_agro_4q', 'E_G_tangible_book_agro_1q_diff_E_G_common_equity_agro_4q']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "3_Xgboost_GoldenFeatures_SelectedFeatures auc 0.888361 trained in 12.29 seconds (1-sample predict time 0.0358 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_GoldenFeatures_SelectedFeatures auc 0.887913 trained in 13.31 seconds (1-sample predict time 0.0365 seconds)\n",
      "7_Xgboost_GoldenFeatures_SelectedFeatures auc 0.884887 trained in 11.36 seconds (1-sample predict time 0.0358 seconds)\n",
      "8_Xgboost_GoldenFeatures auc 0.869772 trained in 17.41 seconds (1-sample predict time 0.055 seconds)\n",
      "9_Xgboost_GoldenFeatures auc 0.868422 trained in 15.83 seconds (1-sample predict time 0.0553 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_GoldenFeatures_SelectedFeatures auc 0.888007 trained in 10.88 seconds (1-sample predict time 0.033 seconds)\n",
      "11_Xgboost_GoldenFeatures_SelectedFeatures auc 0.888238 trained in 14.86 seconds (1-sample predict time 0.0328 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble auc 0.892118 trained in 1.13 seconds (1-sample predict time 0.1297 seconds)\n",
      "AutoML fit time: 266.27 seconds\n",
      "AutoML best model: Ensemble\n",
      "Fenêtre 2020-2025 : entraînement de AutoML...\n",
      "AutoML directory: AutoML_3\n",
      "The task is binary_classification with evaluation metric auc\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost auc 0.889693 trained in 14.57 seconds (1-sample predict time 0.0337 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost auc 0.88546 trained in 15.68 seconds (1-sample predict time 0.0338 seconds)\n",
      "3_Xgboost auc 0.889247 trained in 13.83 seconds (1-sample predict time 0.0356 seconds)\n",
      "4_Xgboost auc 0.86638 trained in 11.22 seconds (1-sample predict time 0.0338 seconds)\n",
      "5_Xgboost auc 0.821975 trained in 8.65 seconds (1-sample predict time 0.0338 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 19\n",
      "Add Golden Feature: E_G_ebt_x_unusual_agro_1q_diff_E_G_retained_earnings_agro_4q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_diff_E_G_issuance_stock_on_assets_ratio\n",
      "Add Golden Feature: E_G_retained_earnings_agro_4q_sum_E_G_other_expenses_agro_4q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_diff_E_G_shares_out_agro_4q\n",
      "Add Golden Feature: E_G_cash_equi_on_assets_ratio_multiply_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_unusual_items_on_assets_ratio_sum_E_G_net_income_inc_on_assets_ratio\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_sum_E_G_assets_gro_five_agro_4q\n",
      "Add Golden Feature: E_G_retained_earnings_agro_4q_sum_E_G_cash_equi_agro_1q\n",
      "Add Golden Feature: E_G_depre_amor_on_assets_ratio_ratio_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_ratio_E_G_interest_expense_on_assets_ratio\n",
      "Add Golden Feature: E_G_working_cap_agro_1q_diff_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_diff_E_G_restructuring_charges_agro_4q\n",
      "Add Golden Feature: E_G_total_intangibles_agro_4q_sum_E_G_common_equity_agro_4q\n",
      "Add Golden Feature: E_G_ops_expenses_on_assets_ratio_ratio_E_G_retained_earnings_agro_4q\n",
      "Add Golden Feature: E_G_retained_earnings_agro_4q_diff_E_G_compre_income_on_assets_ratio\n",
      "Add Golden Feature: E_G_operating_income_agro_1q_diff_E_G_retained_earnings_agro_4q\n",
      "Add Golden Feature: E_G_common_equity_agro_4q_ratio_E_G_cost_borrowing_on_assets_ratio\n",
      "Add Golden Feature: E_G_ebit_agro_1q_diff_E_G_retained_earnings_agro_4q\n",
      "Add Golden Feature: E_G_tangible_book_agro_4q_diff_E_G_cash_acquisitions_on_assets_ratio\n",
      "Created 19 Golden Features in 12.8 seconds.\n",
      "1_Default_Xgboost_GoldenFeatures auc 0.88556 trained in 29.28 seconds (1-sample predict time 0.0575 seconds)\n",
      "3_Xgboost_GoldenFeatures auc 0.890096 trained in 19.54 seconds (1-sample predict time 0.055 seconds)\n",
      "2_Xgboost_GoldenFeatures auc 0.883005 trained in 16.67 seconds (1-sample predict time 0.0546 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "3_Xgboost_GoldenFeatures_RandomFeature auc 0.887082 trained in 19.73 seconds (1-sample predict time 0.0556 seconds)\n",
      "Drop features ['E_G_inventory_agro_4q', 'E_G_minority_int_agro_4q', 'E_G_net_debt_on_assets_ratio', 'E_G_effective_tax_rate_agro_1q', 'E_G_receivables_agro_1q', 'E_G_receivables_on_assets_ratio', 'E_G_tangible_book_agro_1q', 'E_G_working_cap_on_assets_ratio', 'E_G_assets_gro_five_agro_4q', 'E_G_gross_property_on_assets_ratio', 'E_G_shares_out_agro_1q', 'E_G_cash_financing_agro_1q', 'E_G_provision_loan_agro_1q', 'E_G_compre_income_agro_4q', 'E_G_total_liabilities_on_assets_ratio', 'E_G_operating_income_agro_1q_diff_E_G_retained_earnings_agro_4q', 'E_G_rev_gro_five_agro_1q', 'E_G_total_assets_agro_1q', 'E_G_total_revenues_on_assets_ratio', 'E_G_gross_profit_on_assets_ratio', 'E_G_operating_income_agro_4q', 'E_G_interest_expense_on_assets_ratio', 'E_G_net_inc_gro_five_agro_1q', 'E_G_net_income_inc_agro_1q', 'E_G_pref_equity_agro_4q', 'E_G_total_debt_agro_4q', 'E_G_common_equity_on_assets_ratio', 'E_G_shares_out_on_assets_ratio', 'E_G_ebt_x_unusual_agro_4q', 'E_G_cost_borrowing_agro_1q', 'E_G_cash_acquisitions_agro_4q', 'E_G_pref_equity_on_assets_ratio', 'E_G_retained_earnings_agro_1q', 'E_G_net_property_agro_4q', 'E_G_cash_equi_on_assets_ratio_multiply_E_G_common_equity_agro_4q', 'E_G_ops_expenses_on_assets_ratio', 'E_G_common_equity_agro_4q_sum_E_G_assets_gro_five_agro_4q', 'E_G_interest_expense_agro_4q', 'E_G_core_banks_agro_4q', 'E_G_sga_agro_1q', 'E_G_norm_net_inc_on_assets_ratio', 'E_G_def_tax_assets_agro_1q', 'E_G_pref_div_agro_1q', 'E_G_capex_agro_4q', 'E_G_issuance_stock_agro_4q', 'E_G_divestitures_agro_1q', 'E_G_core_banks_agro_1q', 'E_G_provision_loan_on_assets_ratio', 'E_G_tax_expense_on_assets_ratio', 'E_G_total_expenses_agro_4q', 'E_G_total_liabilities_agro_1q', 'E_G_core_banks_on_assets_ratio', 'E_G_pref_equity_agro_1q', 'E_G_pref_div_on_assets_ratio', 'E_G_divestitures_on_assets_ratio', 'E_G_r_d_agro_4q', 'E_G_net_inc_gro_five_agro_4q', 'E_G_provision_loan_agro_4q', 'E_G_r_d_agro_1q', 'E_G_total_expenses_on_assets_ratio', 'E_G_total_expenses_agro_1q', 'E_G_ebitda_agro_4q', 'E_G_ebit_agro_4q', 'E_G_r_d_on_assets_ratio', 'E_G_ops_expenses_agro_4q', 'E_G_asset_writedown_agro_1q', 'E_G_pref_div_agro_4q', 'E_G_total_div_agro_1q', 'E_G_capex_agro_1q', 'E_G_unusual_items_on_assets_ratio', 'E_G_issuance_stock_on_assets_ratio', 'E_G_restructuring_charges_agro_1q', 'E_G_ops_expenses_agro_1q', 'E_G_interest_expense_agro_1q', 'E_G_int_div_income_agro_1q', 'E_G_gross_property_agro_1q', 'random_feature', 'E_G_total_assets_agro_4q', 'E_G_issuance_stock_agro_1q', 'E_G_ebt_x_unusual_agro_1q', 'E_G_def_tax_liability_agro_1q', 'E_G_norm_net_inc_agro_4q', 'E_G_cash_acquisitions_agro_1q', 'E_G_common_equity_agro_4q', 'E_G_total_revenues_agro_4q', 'E_G_cash_investing_agro_1q', 'E_G_cash_equi_agro_1q', 'E_G_asset_writedown_on_assets_ratio', 'E_G_total_capital_agro_1q', 'E_G_ebitda_agro_1q', 'E_G_ops_expenses_on_assets_ratio_ratio_E_G_retained_earnings_agro_4q', 'E_G_shares_out_agro_4q', 'E_G_minority_int_agro_1q', 'E_G_total_capital_agro_4q', 'E_G_tangible_book_agro_4q', 'E_G_restructuring_charges_agro_4q', 'E_G_retained_earnings_agro_4q_diff_E_G_compre_income_on_assets_ratio', 'E_G_common_equity_agro_4q_diff_E_G_shares_out_agro_4q', 'E_G_net_property_agro_1q', 'E_G_net_inc_gro_five_on_assets_ratio', 'E_G_cogs_agro_1q', 'E_G_working_cap_agro_4q', 'E_G_common_equity_agro_4q_diff_E_G_restructuring_charges_agro_4q', 'E_G_tangible_book_agro_4q_diff_E_G_cash_acquisitions_on_assets_ratio', 'E_G_total_revenues_agro_1q', 'E_G_ebit_on_assets_ratio', 'E_G_repurchase_stock_agro_1q', 'E_G_cash_financing_agro_4q', 'E_G_current_liabilities_agro_1q', 'E_G_common_equity_agro_4q_ratio_E_G_interest_expense_on_assets_ratio', 'E_G_operating_income_agro_1q', 'E_G_retained_earnings_agro_4q', 'E_G_retained_earnings_agro_4q_sum_E_G_cash_equi_agro_1q', 'E_G_current_assets_agro_1q', 'E_G_total_intangibles_agro_4q_sum_E_G_common_equity_agro_4q', 'E_G_ebt_x_unusual_on_assets_ratio', 'E_G_common_equity_agro_4q_diff_E_G_issuance_stock_on_assets_ratio', 'E_G_retained_earnings_agro_4q_sum_E_G_other_expenses_agro_4q', 'E_G_depre_amor_on_assets_ratio_ratio_E_G_common_equity_agro_4q', 'E_G_ebit_agro_1q_diff_E_G_retained_earnings_agro_4q', 'E_G_working_cap_agro_1q_diff_E_G_common_equity_agro_4q']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "3_Xgboost_GoldenFeatures_SelectedFeatures auc 0.899827 trained in 12.49 seconds (1-sample predict time 0.0303 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_GoldenFeatures_SelectedFeatures auc 0.898523 trained in 12.96 seconds (1-sample predict time 0.0302 seconds)\n",
      "7_Xgboost_GoldenFeatures_SelectedFeatures auc 0.897695 trained in 10.5 seconds (1-sample predict time 0.0301 seconds)\n",
      "8_Xgboost_GoldenFeatures auc 0.884158 trained in 20.03 seconds (1-sample predict time 0.0544 seconds)\n",
      "9_Xgboost_GoldenFeatures auc 0.886671 trained in 14.63 seconds (1-sample predict time 0.0569 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_GoldenFeatures_SelectedFeatures auc 0.90295 trained in 11.75 seconds (1-sample predict time 0.03 seconds)\n",
      "11_Xgboost_GoldenFeatures_SelectedFeatures auc 0.9023 trained in 13.44 seconds (1-sample predict time 0.0303 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble auc 0.905888 trained in 1.11 seconds (1-sample predict time 0.1538 seconds)\n",
      "AutoML fit time: 261.96 seconds\n",
      "AutoML best model: Ensemble\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pipeline_rolling_windows(\n",
    "    data=df_test, \n",
    "    date_col=\"date\", \n",
    "    target_col=\"binary_target_net_income\", \n",
    "    train_years=2, \n",
    "    val_years=1, \n",
    "    test_years=1, \n",
    "    buffer_months=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"df_can_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assure que les colonnes 'date' sont au bon format datetime dans les deux DataFrames\n",
    "predictions_df['date'] = pd.to_datetime(predictions_df['date'])\n",
    "df_canada['date'] = pd.to_datetime(df_canada['date'])\n",
    "\n",
    "# Faire la jointure sur 'cid' et 'date'\n",
    "merged_df = predictions_df.merge(df_canada[['cid', 'date', 'return_1q']], on=['cid', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weighted_portfolios(predictions_df, df_canada, return_col, lower_threshold=0.4, upper_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Crée un portefeuille pondéré basé sur les prédictions et calcule les rendements pondérés par année,\n",
    "    en attribuant des poids positifs aux positions longues et négatifs aux positions courtes, avec une somme neutre.\n",
    "    \n",
    "    Args:\n",
    "    - predictions_df (pd.DataFrame): DataFrame contenant les prédictions et les identifiants 'cid'.\n",
    "    - df_canada (pd.DataFrame): DataFrame contenant les rendements futurs et les identifiants 'cid'.\n",
    "    - return_col (str): Nom de la colonne des rendements futurs dans df_canada.\n",
    "    - lower_threshold (float): Seuil inférieur pour les positions courtes.\n",
    "    - upper_threshold (float): Seuil supérieur pour les positions longues.\n",
    "    \n",
    "    Returns:\n",
    "    - result_df (pd.DataFrame): DataFrame contenant les rendements pondérés des portefeuilles par année.\n",
    "    \"\"\"\n",
    "    # Joindre les deux DataFrames sur 'cid' et 'date'\n",
    "    merged_df = predictions_df.merge(df_canada[['cid', 'date', return_col]], on=['cid', 'date'], how='left')\n",
    "    \n",
    "    # Extraire l'année à partir de la colonne 'date'\n",
    "    merged_df['year'] = merged_df['date'].dt.year\n",
    "    \n",
    "    # Retirer les lignes avec des valeurs manquantes\n",
    "    merged_df.dropna(inplace=True)\n",
    "    \n",
    "    # Initialiser une liste pour stocker les résultats\n",
    "    results = []\n",
    "\n",
    "    # Grouper par année\n",
    "    for year, group in merged_df.groupby('year'):\n",
    "        # Sélectionner les positions longues et courtes selon les seuils\n",
    "        selected_long = group[group['proba_class_1'] > upper_threshold]  # Positions longues\n",
    "        selected_short = group[group['proba_class_1'] < lower_threshold]  # Positions courtes\n",
    "        \n",
    "        n_long = len(selected_long)\n",
    "        n_short = len(selected_short)\n",
    "        \n",
    "        if n_long > 0 or n_short > 0:\n",
    "            # Attribuer des poids aux positions longues et courtes\n",
    "            if n_long > 0:\n",
    "                selected_long.loc[:, 'weight'] = 1 / n_long  # Poids positifs pour les positions longues\n",
    "            if n_short > 0:\n",
    "                selected_short.loc[:, 'weight'] = -1 / n_short  # Poids négatifs pour les positions courtes\n",
    "            \n",
    "            # Combiner les deux DataFrames\n",
    "            selected = pd.concat([selected_long, selected_short], ignore_index=True)\n",
    "            \n",
    "            # Calculer le rendement pondéré du portefeuille (somme des rendements pondérés)\n",
    "            weighted_return = (selected['weight'] * selected[return_col]).sum()\n",
    "            \n",
    "            # Ajouter le résultat à la liste\n",
    "            results.append({'year': year, 'weighted_return': weighted_return})\n",
    "        else:\n",
    "            # Si aucune action ne respecte les seuils, le rendement est NaN\n",
    "            results.append({'year': year, 'weighted_return': float('nan')})\n",
    "\n",
    "    # Convertir les résultats en DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_2325/1547445209.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_2325/1547445209.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_2325/1547445209.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_2325/1547445209.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weighted_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.006834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>-0.016857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  weighted_return\n",
       "0  2023         0.006834\n",
       "1  2024        -0.016857"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_returns = create_weighted_portfolios(predictions_df, df_canada, 'return_1q', lower_threshold=0.4, upper_threshold=0.6)\n",
    "test_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fonction rendement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire l'année à partir de la colonne 'date'\n",
    "merged_df['year'] = merged_df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2023    1396\n",
      "2024    1056\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Voir les valeurs uniques et leur compte dans la colonne 'cid'\n",
    "value_counts = merged_df['year'].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Année 2023 : 1396 lignes avant sélection\n",
      "Année 2023 : 1197 lignes après sélection\n",
      "Année 2024 : 1056 lignes avant sélection\n",
      "Année 2024 : 878 lignes après sélection\n"
     ]
    }
   ],
   "source": [
    "selected_by_year = {}  # Dictionnaire pour stocker les DataFrames selected par année\n",
    "\n",
    "for year, group in merged_df.groupby('year'):\n",
    "    print(f\"Année {year} : {group.shape[0]} lignes avant sélection\")\n",
    "    \n",
    "    # Appliquer la formule de sélection\n",
    "    selected_long = group[group['proba_class_1'] > 0.6]  # Positions longues\n",
    "    selected_short = group[group['proba_class_1'] < 0.4]  # Positions courtes\n",
    "    \n",
    "    # Combiner les positions longues et courtes\n",
    "    selected = pd.concat([selected_long, selected_short], ignore_index=True)\n",
    "    \n",
    "    print(f\"Année {year} : {selected.shape[0]} lignes après sélection\")\n",
    "    \n",
    "    if len(selected) > 0:\n",
    "        # Calcul des poids pour les positions longues\n",
    "        n_long = len(selected_long)\n",
    "        n_short = len(selected_short)\n",
    "        \n",
    "        if n_long > 0:\n",
    "            selected.loc[selected['proba_class_1'] > 0.6, 'weight'] = 1 / n_long\n",
    "        if n_short > 0:\n",
    "            selected.loc[selected['proba_class_1'] < 0.4, 'weight'] = -1 / n_short\n",
    "        \n",
    "        # Calculer le rendement pondéré pour cette année (pondérer return_1q par les poids)\n",
    "        selected['weighted_return'] = selected['weight'] * selected['return_1q']\n",
    "        \n",
    "        # Vérifier la somme des poids (elle doit être proche de 0)\n",
    "        total_weight = selected['weight'].sum()\n",
    "        selected['weight_check'] = total_weight\n",
    "        selected['weight_valid'] = abs(total_weight) < 1e-6  # Tolérance d'erreur\n",
    "        \n",
    "    else:\n",
    "        # Si aucune action sélectionnée, ajouter les colonnes avec NaN\n",
    "        selected['weight'] = np.nan\n",
    "        selected['return_1q'] = np.nan\n",
    "        selected['weighted_return'] = np.nan\n",
    "        selected['weight_check'] = np.nan\n",
    "        selected['weight_valid'] = False\n",
    "    \n",
    "    # Stocker le DataFrame dans le dictionnaire\n",
    "    selected_by_year[year] = selected.copy()\n",
    "\n",
    "# Exporter chaque DataFrame selected avec les vérifications dans des fichiers CSV\n",
    "for year, df in selected_by_year.items():\n",
    "    df.to_csv(f\"selected_{year}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HECFinance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
