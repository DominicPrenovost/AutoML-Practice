{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from supervised.automl import AutoML\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/nlrkcsjd7j70p9jvf2jl5t4c0000gn/T/ipykernel_1268/963998424.py:9: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sid</th>\n",
       "      <th>market_cap_usd</th>\n",
       "      <th>price_close_usd</th>\n",
       "      <th>trading_volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>7656.684843</td>\n",
       "      <td>269.495966</td>\n",
       "      <td>99751.607112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>7034.937130</td>\n",
       "      <td>286.285815</td>\n",
       "      <td>89309.943437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>3820.692249</td>\n",
       "      <td>14.367600</td>\n",
       "      <td>64749.312249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>4933.317771</td>\n",
       "      <td>117.037847</td>\n",
       "      <td>62656.894901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>SID-0000</td>\n",
       "      <td>5043.224278</td>\n",
       "      <td>208.838595</td>\n",
       "      <td>27811.480074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       sid  market_cap_usd  price_close_usd  trading_volume  \\\n",
       "0 2015-03-31  SID-0000     7656.684843       269.495966    99751.607112   \n",
       "1 2015-06-30  SID-0000     7034.937130       286.285815    89309.943437   \n",
       "2 2015-09-30  SID-0000     3820.692249        14.367600    64749.312249   \n",
       "3 2015-12-31  SID-0000     4933.317771       117.037847    62656.894901   \n",
       "4 2016-03-31  SID-0000     5043.224278       208.838595    27811.480074   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_dataset(n_actions=50, start_date=\"2010-01-01\", end_date=\"2020-12-31\"):\n",
    "    \"\"\"\n",
    "    Génère un DataFrame fictif avec des données temporelles pour plusieurs actions.\n",
    "    - n_actions : nombre d'actions uniques (identifiants `sid`).\n",
    "    - start_date : date de début.\n",
    "    - end_date : date de fin.\n",
    "    \"\"\"\n",
    "    # Générer une plage de dates quotidienne\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=\"Q\")  # Fréquence trimestrielle\n",
    "    \n",
    "    # Générer des identifiants pour les actions\n",
    "    sids = [f\"SID-{i:04d}\" for i in range(n_actions)]\n",
    "    \n",
    "    # Liste pour stocker les données\n",
    "    data = []\n",
    "    \n",
    "    for sid in sids:\n",
    "        for date in date_range:\n",
    "            # Générer des valeurs aléatoires pour les variables explicatives et la cible\n",
    "            market_cap_usd = np.random.uniform(100, 10000)  # Capitalisation aléatoire\n",
    "            price_close_usd = np.random.uniform(10, 500)    # Prix de clôture\n",
    "            trading_volume = np.random.uniform(1000, 100000)  # Volume de trading\n",
    "            target = np.random.choice([0, 1])  # Variable cible (0 ou 1)\n",
    "            \n",
    "            # Ajouter la ligne au dataset\n",
    "            data.append([date, sid, market_cap_usd, price_close_usd, trading_volume, target])\n",
    "    \n",
    "    # Convertir en DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"date\", \"sid\", \"market_cap_usd\", \"price_close_usd\", \"trading_volume\", \"target\"])\n",
    "    return df\n",
    "\n",
    "# Générer un dataset fictif\n",
    "df_random = generate_random_dataset(n_actions=10, start_date=\"2015-01-01\", end_date=\"2020-12-31\")\n",
    "\n",
    "# Afficher un aperçu\n",
    "df_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rolling_windows(data, date_col, target_col, train_years, val_years, test_years, buffer_months=0):\n",
    "    \"\"\"\n",
    "    Pipeline direct pour la rolling window avec AutoML et cross-validation personnalisée.\n",
    "    Ajoute les périodes dans le DataFrame final pour validation.\n",
    "    \"\"\"\n",
    "    # Conversion de la colonne date\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    start_date = data[date_col].min()\n",
    "    end_date = data[date_col].max()\n",
    "\n",
    "    predictions_all = []  # Liste pour stocker toutes les prédictions\n",
    "\n",
    "    while start_date + relativedelta(years=train_years + val_years + test_years) <= end_date:\n",
    "        # Définir les périodes\n",
    "        train_end = start_date + relativedelta(years=train_years) - pd.Timedelta(days=1)\n",
    "        tampon_1_end = train_end + relativedelta(months=buffer_months)\n",
    "        val_start = tampon_1_end + pd.Timedelta(days=1)\n",
    "        val_end = val_start + relativedelta(years=val_years) - pd.Timedelta(days=1)\n",
    "        tampon_2_end = val_end + relativedelta(months=buffer_months)\n",
    "        test_start = tampon_2_end + pd.Timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=test_years) - pd.Timedelta(days=1)\n",
    "\n",
    "        # Filtrer les données\n",
    "        train_data = data.loc[(data[date_col] >= start_date) & (data[date_col] <= train_end)]\n",
    "        val_data = data.loc[(data[date_col] >= val_start) & (data[date_col] <= val_end)]\n",
    "        test_data = data.loc[(data[date_col] >= test_start) & (data[date_col] <= test_end)]\n",
    "\n",
    "        if len(train_data) == 0 or len(val_data) == 0 or len(test_data) == 0:\n",
    "            print(f\"Fenêtre {start_date.year}-{test_end.year} : données insuffisantes, sautée.\")\n",
    "            start_date += relativedelta(years=1)\n",
    "            continue\n",
    "\n",
    "        # Configurer et entraîner AutoML\n",
    "        print(f\"Fenêtre {start_date.year}-{test_end.year} : entraînement de AutoML...\")\n",
    "        automl = AutoML(mode=\"Perform\", algorithms=[\"Xgboost\"])\n",
    "        custom_cv = [(train_data.index, val_data.index)]\n",
    "        automl.fit(\n",
    "            train_data.drop(columns=[target_col, date_col]),\n",
    "            train_data[target_col], cv=custom_cv\n",
    "        )\n",
    "\n",
    "        # Prédire sur le test set\n",
    "        test_preds = test_data[[date_col, target_col]].copy()\n",
    "        test_preds[\"predicted\"] = automl.predict(test_data.drop(columns=[target_col, date_col]))\n",
    "        test_preds[\"window\"] = f\"{start_date.year}-{test_end.year}\"\n",
    "        test_preds[\"sid\"] = test_data[\"sid\"].values\n",
    "\n",
    "        # Ajouter les périodes pour validation\n",
    "        test_preds[\"train_start\"] = start_date\n",
    "        test_preds[\"train_end\"] = train_end\n",
    "        test_preds[\"tampon_1\"] = tampon_1_end\n",
    "        test_preds[\"val_start\"] = val_start\n",
    "        test_preds[\"val_end\"] = val_end\n",
    "        test_preds[\"tampon_2\"] = tampon_2_end\n",
    "        test_preds[\"test_start\"] = test_start\n",
    "        test_preds[\"test_end\"] = test_end\n",
    "\n",
    "        # Sauvegarder les prédictions\n",
    "        predictions_all.append(test_preds)\n",
    "\n",
    "        # Avancer la fenêtre\n",
    "        start_date += relativedelta(years=1)\n",
    "\n",
    "    predictions_df = pd.concat(predictions_all, ignore_index=True)\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fenêtre 2015-2019 : entraînement de AutoML...\n",
      "AutoML directory: AutoML_3\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.700701 trained in 6.15 seconds (1-sample predict time 0.0068 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.693284 trained in 3.48 seconds (1-sample predict time 0.0068 seconds)\n",
      "3_Xgboost logloss 0.704036 trained in 1.46 seconds (1-sample predict time 0.0062 seconds)\n",
      "4_Xgboost logloss 0.691386 trained in 1.01 seconds (1-sample predict time 0.0065 seconds)\n",
      "5_Xgboost logloss 0.691386 trained in 1.02 seconds (1-sample predict time 0.007 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: trading_volume_multiply_price_close_usd\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_price_close_usd\n",
      "Add Golden Feature: trading_volume_sum_price_close_usd\n",
      "Add Golden Feature: trading_volume_sum_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_diff_price_close_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_ratio_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "4_Xgboost_GoldenFeatures logloss 0.691386 trained in 1.18 seconds (1-sample predict time 0.0175 seconds)\n",
      "5_Xgboost_GoldenFeatures logloss 0.691386 trained in 1.21 seconds (1-sample predict time 0.0176 seconds)\n",
      "2_Xgboost_GoldenFeatures logloss 0.689153 trained in 1.45 seconds (1-sample predict time 0.0174 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "2_Xgboost_GoldenFeatures_RandomFeature logloss 0.691557 trained in 1.57 seconds (1-sample predict time 0.0194 seconds)\n",
      "Drop features ['sid', 'market_cap_usd', 'price_close_usd', 'trading_volume', 'trading_volume_multiply_price_close_usd', 'market_cap_usd_ratio_price_close_usd', 'trading_volume_sum_price_close_usd', 'trading_volume_sum_market_cap_usd', 'market_cap_usd_diff_price_close_usd', 'market_cap_usd_ratio_trading_volume', 'trading_volume_ratio_market_cap_usd', 'price_close_usd_diff_trading_volume', 'random_feature', 'price_close_usd_ratio_market_cap_usd']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "2_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.618603 trained in 7.7 seconds (1-sample predict time 0.0105 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.620003 trained in 8.22 seconds (1-sample predict time 0.0102 seconds)\n",
      "7_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.617855 trained in 8.52 seconds (1-sample predict time 0.0105 seconds)\n",
      "8_Xgboost_GoldenFeatures logloss 0.688868 trained in 1.72 seconds (1-sample predict time 0.0175 seconds)\n",
      "9_Xgboost_GoldenFeatures logloss 0.689851 trained in 1.76 seconds (1-sample predict time 0.0169 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.617855 trained in 8.74 seconds (1-sample predict time 0.0102 seconds)\n",
      "11_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.618603 trained in 7.68 seconds (1-sample predict time 0.0106 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.617855 trained in 0.87 seconds (1-sample predict time 0.0104 seconds)\n",
      "AutoML fit time: 74.59 seconds\n",
      "AutoML best model: 7_Xgboost_GoldenFeatures_SelectedFeatures\n",
      "Fenêtre 2016-2020 : entraînement de AutoML...\n",
      "AutoML directory: AutoML_4\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.682801 trained in 1.75 seconds (1-sample predict time 0.0067 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.695165 trained in 1.18 seconds (1-sample predict time 0.0061 seconds)\n",
      "3_Xgboost logloss 0.696592 trained in 1.53 seconds (1-sample predict time 0.0067 seconds)\n",
      "4_Xgboost logloss 0.692951 trained in 0.93 seconds (1-sample predict time 0.0065 seconds)\n",
      "5_Xgboost logloss 0.692951 trained in 0.94 seconds (1-sample predict time 0.0068 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: market_cap_usd_ratio_price_close_usd\n",
      "Add Golden Feature: price_close_usd_diff_trading_volume\n",
      "Add Golden Feature: trading_volume_multiply_market_cap_usd\n",
      "Add Golden Feature: market_cap_usd_ratio_trading_volume\n",
      "Add Golden Feature: price_close_usd_multiply_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_market_cap_usd\n",
      "Add Golden Feature: price_close_usd_ratio_trading_volume\n",
      "Add Golden Feature: trading_volume_sum_market_cap_usd\n",
      "Add Golden Feature: trading_volume_ratio_market_cap_usd\n",
      "Add Golden Feature: trading_volume_ratio_price_close_usd\n",
      "Created 10 Golden Features in 0.01 seconds.\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.694467 trained in 1.72 seconds (1-sample predict time 0.0171 seconds)\n",
      "4_Xgboost_GoldenFeatures logloss 0.692951 trained in 1.09 seconds (1-sample predict time 0.0166 seconds)\n",
      "5_Xgboost_GoldenFeatures logloss 0.692951 trained in 1.16 seconds (1-sample predict time 0.0174 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "1_Default_Xgboost_RandomFeature logloss 0.696119 trained in 1.71 seconds (1-sample predict time 0.0081 seconds)\n",
      "Drop features ['random_feature', 'price_close_usd', 'market_cap_usd', 'trading_volume']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "1_Default_Xgboost_SelectedFeatures logloss 0.680754 trained in 1.94 seconds (1-sample predict time 0.0056 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_SelectedFeatures logloss 0.680089 trained in 1.93 seconds (1-sample predict time 0.0055 seconds)\n",
      "7_Xgboost_SelectedFeatures logloss 0.681435 trained in 1.95 seconds (1-sample predict time 0.0049 seconds)\n",
      "8_Xgboost logloss 0.684833 trained in 1.97 seconds (1-sample predict time 0.0066 seconds)\n",
      "9_Xgboost logloss 0.690278 trained in 1.97 seconds (1-sample predict time 0.0062 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_SelectedFeatures logloss 0.680089 trained in 2.27 seconds (1-sample predict time 0.0053 seconds)\n",
      "11_Xgboost_SelectedFeatures logloss 0.680754 trained in 2.2 seconds (1-sample predict time 0.0053 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.675536 trained in 0.87 seconds (1-sample predict time 0.011 seconds)\n",
      "AutoML fit time: 36.88 seconds\n",
      "AutoML best model: Ensemble\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pipeline_rolling_windows(\n",
    "    data=df_random, \n",
    "    date_col=\"date\", \n",
    "    target_col=\"target\", \n",
    "    train_years=2, \n",
    "    val_years=1, \n",
    "    test_years=1, \n",
    "    buffer_months=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"pred_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HECFinance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
